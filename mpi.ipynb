{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several exercises: Jupyter Notebook, iPython and ipyparallel, and HPC MPICH\n",
    "\n",
    "The content of this notebook is borrowed extensively from Daan Van Hauwermeiren, from his tutotial of ipyparallel, stored on github https://github.com/DaanVanHauwermeiren/ipyparallel-tutorial/blob/master/02-ipyparallel-tutorial-direct-interface.ipynb.  Many adaptions have been made to accommodate this demonstration and this HPC MPI environment.\n",
    "\n",
    "Prior to running these steps in this notebook, the following details must\n",
    "be completed outside the context of Jupyter, and generally will need to be \n",
    "facilitated by a systems administator with appropriate rights and knowledge \n",
    "of HPC and MPI.\n",
    "\n",
    "  1) HPC and MPICH have been configured, with compute nodes running\n",
    "  2) Related to HPC and MPICH, an NFS/NIS environment exists to facilitate the 'scientist' user environment across all of the computing resources in the cluster\n",
    "  3) The ipyparallel client/engine environment must be configured and started that supports MPI/MPICH\n",
    "  4) Ensure that the \"IPython Cluster\" called \"mpi\" in the JupyterHub is running\n",
    "\n",
    "Once the above details have been acomplished, import the IPython ipyparallel module and create a Client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the IPython ipyparallel module and create a Client instance\n",
    "# In this demonstration, an MPI-oriented client is created, referenced by the 'mpi' profile\n",
    "# There are 4 mpi engines that have been configured and running on 4 separate HPC compute nodes\n",
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')\n",
    "\n",
    "# Show that there are engines running, responding\n",
    "rc.ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ipyparallel object, constructed via list-access to the client:\n",
    " vobject = rc[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python’s builtin map() functions allows a function to be applied to a sequence element-by-element. This type of code is typically trivial to parallelize. In fact, since IPython’s interface is all about functions anyway, you can just use the builtin map() with a RemoteFunction, or a vobject’s map() method.\n",
    "\n",
    "do an arbitrary serial computation using just the power of the HPC head node, \n",
    "... and show how long it takes to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 µs, sys: 3 µs, total: 21 µs\n",
      "Wall time: 25.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "serial_result = list(map(lambda x:x**2**2, range(30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same computation using the MPI compute nodes HPC cluster, \n",
    "... and show how long it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 53.1 ms, total: 229 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parallel_result = vobject.map_sync(lambda x:x**2**2, range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial_result==parallel_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote function decorators\n",
    "\n",
    "Remote functions are just like normal functions, but when they are called, they execute on one or more engines, rather than locally.  Here we will demonstrate the @parallel function decorator, which creates parallel functions that break up an element-wise operations and distribute them to remote workers.  It also reconstructs the result from each worker as the result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we'll enable blocking, which will be explored more throughly later.  \n",
    "# In short, blocking will ensure that each task won't proceed until all the remotely distributed work is complete.\n",
    "@vobject.remote(block=True)\n",
    "\n",
    "# Define a function called \"getpid\" that ... well, you can see the description\n",
    "def getpid():\n",
    "    '''\n",
    "    import library os and return the process number (pid) corresponding with\n",
    "    the execution\n",
    "    '''\n",
    "    import os\n",
    "    return os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17653, 5950, 5785, 5685]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using our newly defined function, show the process id of the engine running on each compute node\n",
    "getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use numpy to create some complicated (random) arrays, then use those arrays for some big computations that should benefit by some distributed HPC compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.random.random((64,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a little function that can do the calculations as a distribution among multiple, parallel compute nodes\n",
    "@vobject.parallel(block=True)\n",
    "def pmul(A,B):\n",
    "    return A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to compare the amount of time it takes to do the calulation locally on the HPC head\n",
    "and the amount of time it takes to do the calculation among the distributed compute nodes\n",
    "\n",
    "First, do the calculation locally, then do it remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 µs, sys: 6 µs, total: 33 µs\n",
      "Wall time: 37.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C_local = A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 ms, sys: 51 µs, total: 20.3 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C_remote = pmul(A,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C_local == C_remote).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple, new function that can be called locally but that will execute remotely, in parallel.\n",
    "It's just a simple instruction that will \"echo\" the output of what is run on the remote worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vobject.parallel(block=True)\n",
    "def echo(x):\n",
    "     return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['range(0, 2)', 'range(2, 3)', 'range(3, 4)', 'range(4, 5)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo.map(range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking execution\n",
    "\n",
    "In blocking mode, the iPython ipyparallel object (called vobject in these examples; defined at the beginning of this notebook) submits the command to the controller, which places the command in the engines’ queues for execution. The apply() call then blocks until the engines are done executing the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apply', 'apply_async', 'apply_sync']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show function names (on the remote worker) that beging with the string \"apply\"\n",
    "[x for x in dir(vobject) if x.startswith('apply')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 42, 42, 42]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject.block = True\n",
    "vobject['a'] = 5\n",
    "vobject['b'] = 10\n",
    "vobject.apply(lambda x: a+b+x, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 42, 42, 42]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject.block = False\n",
    "vobject.apply_sync(lambda x: a+b+x, 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python commands can be executed as strings on specific engines by using a vobject’s execute method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc[::2].execute('c=a+b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc[1::2].execute('c=a-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, -5, 15, -5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject['c'] # shorthand for vobject.pull('c', block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-blocking execution\n",
    "\n",
    "In non-blocking mode, apply() submits the command to be executed and then returns a AsyncResult object immediately. The AsyncResult object gives you a way of getting a result at a later time through its get() method.\n",
    "\n",
    "More info on the AsyncResult object: http://ipyparallel.readthedocs.io/en/6.0.2/asyncresult.html#parallel-asyncresult\n",
    "\n",
    "This allows you to quickly submit long running commands without blocking your local Python/IPython session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our function\n",
    "def wait(t):\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    time.sleep(t)\n",
    "    return time.time()-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In non-blocking mode\n",
    "ar = vobject.apply_async(wait, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0031118392944336, 3.003131151199341, 3.0031638145446777, 3.0031161308288574]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now block for the result, and the output won't disply until after 3 seconds\n",
    "ar.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again in non-blocking mode, with longer wait (10 seconds)\n",
    "ar = vobject.apply_async(wait, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poll to see if the result is ready\n",
    "# If you run this fast enough following the previous step, the output will be \"False\"\n",
    "# But if you wait for 10 seconds, before executing this step, the output will be \"True\"\n",
    "ar.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.010129928588867, 10.01012921333313, 10.01011323928833, 10.010184049606323]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask for the result, but wait a maximum of 1 second:\n",
    "ar.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it is desirable to wait until a set of AsyncResult objects are done. For this, there is the method wait(). This method takes a tuple of AsyncResult objects (or msg_ids or indices to the client’s History), and blocks until all of the associated results are ready.\n",
    "\n",
    "In proper Jupyter Notebook fashion, the step progress indicator will show as a '*' character until the instruction is completed.  Output will not be displayed until the instruction is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0031027793884277, 3.0031118392944336, 3.0030837059020996, 3.003117322921753]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject.block=False\n",
    "# A trivial list of AsyncResults objects\n",
    "pr_list = [vobject.apply_async(wait, 3) for i in range(10)]\n",
    "# Wait until all of the clients have completed the instruction\n",
    "vobject.wait(pr_list)\n",
    "# Then, their results are ready using get() or the `.r` attribute\n",
    "pr_list[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter and gather\n",
    "\n",
    "Sometimes it is useful to partition a sequence and push the partitions to different engines. In MPI language, this is know as scatter/gather and we follow that terminology. However, it is important to remember that in IPython’s Client class, scatter() is from the interactive IPython session to the engines and gather() is from the engines back to the interactive IPython session. For scatter/gather operations between engines, MPI, pyzmq, or some other direct interconnect should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: scatter>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject.scatter('a',range(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 4), range(4, 8), range(8, 12), range(12, 16)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncMapResult: gather>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vobject.gather('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parallel list comprehensions\n",
    "\n",
    "In many cases list comprehensions are nicer than using the map function. While we don’t have fully parallel list comprehensions, it is simple to get the basic effect using scatter() and gather():\n",
    "\n",
    "The %px magic executes a single Python command on the engines specified by the targets attribute of the view instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210832519264920576, 253295162119140625, 303305489096114176, 362033331456891249, 430804206899405824, 511116753300641401, 604661760000000000, 713342911662882601, 839299365868340224, 984930291881790849]\n"
     ]
    }
   ],
   "source": [
    "vobject.scatter('x', range(64))\n",
    "#Parallel execution on engines: [0, 1, 2, 3]\n",
    "%px y = [i**10 for i in x]\n",
    "y = vobject.gather('y')\n",
    "print(y.get()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example: monte carlo approximation of pi\n",
    "\n",
    "A simple toy problem to get a handle on multiple engines is a Monte Carlo approximation of π.\n",
    "\n",
    "Let’s say we have a dartboard with a round target inscribed on a square board. If you threw darts randomly, and they land evenly distributed on the square board, how many darts would you expect to hit the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from math import pi\n",
    "vobject['random'] = random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcpi(nsamples):\n",
    "    s = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random()\n",
    "        y = random()\n",
    "        if x*x + y*y <= 1:\n",
    "            s+=1\n",
    "    return 4.*s/nsamples\n",
    "    \n",
    "def multi_mcpi(view, nsamples):\n",
    "    p = len(view.targets)\n",
    "    if nsamples % p:\n",
    "        # ensure even divisibility\n",
    "        nsamples += p - (nsamples%p)\n",
    "    \n",
    "    subsamples = nsamples//p\n",
    "    \n",
    "    ar = view.apply(mcpi, subsamples)\n",
    "    return sum(ar)/p\n",
    "\n",
    "def check_pi(tol=1e-5, step=10, verbose=False):\n",
    "    guess = 0\n",
    "    spi = pi\n",
    "    steps = 0\n",
    "    while abs(spi-guess)/spi > tol:\n",
    "        for i in range(step):\n",
    "            x = random()\n",
    "            y = random()\n",
    "            if x*x+y*y <= 1:\n",
    "                guess += 4.\n",
    "        steps += step\n",
    "        spi = pi*steps\n",
    "        if verbose:\n",
    "            print(spi, guess, abs(spi-guess)/spi)\n",
    "    return steps, guess/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 37s, sys: 0 ns, total: 5min 37s\n",
      "Wall time: 5min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141515788"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mcpi(int(1e9))\n",
    "# 1e7 means 10 to the 7th power.  \"e\" stands for \"expontent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 0 ns, total: 21.4 ms\n",
      "Wall time: 872 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1411488"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "multi_mcpi(vobject, int(1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3.1416)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
